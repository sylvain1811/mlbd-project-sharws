{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLBD Project : Simplified Human Activity Recognition w/Smartphone\n",
    "\n",
    "1. Feature selection\n",
    "2. Model\n",
    "3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data_train = pd.read_csv(\"dataset/train.csv\")\n",
    "# data_test = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Separate X and y\n",
    "X = data_train.values[:,2:]\n",
    "y_label = data_train.values[:,1]\n",
    "\n",
    "# Encode y\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y_label)\n",
    "\n",
    "# Split dataset to test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"X_train : {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "print(y.max(), y.min())\n",
    "    \n",
    "plt.figure(figsize=(15,10))\n",
    "bins = range(7)\n",
    "plt.hist(y, bins=bins,rwidth=0.5)\n",
    "bins_labels(bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a list that will contain all lists of features indexes resulting of different feature selection implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_indexes = []\n",
    "list_indexes.append([x for x in range(X_train.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceThreshold feature selection\n",
    "\n",
    "We remove features with low variance. Here we keep only features with variance greater than 20%, so it will remove all features that have a high probability of beeing similar along the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(0.2))\n",
    "X_train_selected = sel.fit_transform(X_train)\n",
    "indices = sel.get_support(indices=True)\n",
    "print(X_train_selected.shape)\n",
    "\n",
    "list_indexes.append(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection\n",
    "\n",
    "We only keep the K features with highest score. Score is computed using statistical method, here we use chi2.\n",
    "Chi2 need variables to be non-neative. As all variables are in the interval [-1,1] we can simply add 1 to all variables for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "kbest=SelectKBest(chi2, k=150)\n",
    "# All features are [-1,1] but this must be non-negative, so we add 1 to all features\n",
    "X_train_selected = kbest.fit_transform(X_train + 1, y_train)\n",
    "indices = kbest.get_support(indices=True)\n",
    "print(X_train_selected.shape)\n",
    "\n",
    "list_indexes.append(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "First, we delcare our results dictionnary. Then, for each classifier, we will iteratre through `list_indexes`, train and compute accuracy, and finally push the result inside the `results` dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=8)\n",
    "params = {\"n_neighbors\": [1,3,5,7], \"p\": [1,2,3], \"leaf_size\": [5, 10, 30, 60]}\n",
    "\n",
    "\n",
    "results_knn = {}\n",
    "\n",
    "for i, indexes in enumerate(list_indexes):\n",
    "    clf = GridSearchCV(knn, params, cv=5)\n",
    "\n",
    "    clf.fit(X_train[:,indexes], y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_test[:,indexes])\n",
    "\n",
    "    score = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print(score)\n",
    "    print(cm)\n",
    "\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    results_knn[i]={\"accuracy\":score,\"conf_mat\":cm}\n",
    "\n",
    "results[\"knn\"] = results_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 10), random_state=1)\n",
    "params = {\"solver\":[\"lbfgs\"], \"alpha\":[1e-5, 1e-4,1e-3,1e-6], \n",
    "          \"hidden_layer_sizes\":[(5,10)], \"max_iter\":[200,250,300]}\n",
    "\n",
    "results_mlp={}\n",
    "\n",
    "for i, indexes in enumerate(list_indexes):\n",
    "    clf = GridSearchCV(mlpc, params, cv=5)\n",
    "\n",
    "    clf.fit(X_train[:,indexes], y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_test[:,indexes])\n",
    "\n",
    "    score = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print(score)\n",
    "    print(cm)\n",
    "\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    results_mlp[i]={\"accuracy\":score,\"conf_mat\":cm}\n",
    "\n",
    "results[\"mlp\"]=results_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "params = {\"C\":[0.1, 0.5, 1.0, 2.0, 10.0, 50.0, 100.0, 200.0, 500.0, 1000.0], \n",
    "          \"kernel\":['linear', 'rbf', 'sigmoid'], 'decision_function_shape':['ovo','ovr']}\n",
    "\n",
    "svc = svm.SVC(gamma='scale')\n",
    "\n",
    "results_svm={}\n",
    "\n",
    "for i, indexes in enumerate(list_indexes):\n",
    "    clf = GridSearchCV(svc, params, cv=5)\n",
    "\n",
    "    clf.fit(X_train[:,indexes], y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_test[:,indexes])\n",
    "\n",
    "    score = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print(score)\n",
    "    print(cm)\n",
    "\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    results_svm[i]={\"accuracy\":score,\"conf_mat\":cm}\n",
    "\n",
    "results[\"svm\"]=results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
